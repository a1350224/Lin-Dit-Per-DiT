# Lin-Dit-Per-DiT
Here is a document about image generation models with improved attention mechanism. Diffsuion Transformer is improved mainly based on the attention mechanism of Performer and Linformer.

This project aims to study whether the improved attention mechanism can optimize the diffusion model to generate high-resolution images. Experiments are carried out from two aspects of memory occupancy and image score, and the task of DiT, Lin-DiT and Per-DiT to generate high-resolution images on the DIV2K dataset is explored.
